{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235846e5",
   "metadata": {},
   "source": [
    "<hr style=\"border:10px solid gray\">\n",
    "\n",
    "# Simple running example of DAHSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8fd8c8",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "⚠️ In order to run this notebook, you need to have installed all the dependancies needed to run DAHSI as listed in the $\\texttt{README.md}$ file in this repository.\n",
    "\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "⚠️ This notebook is for illustration of the method purposes only and so the toy problem chosen contains no hidden variables to be able to go through the code in a few minutes. This notebook will give you the tools and understanding necessary to be able to build your own problem and solve it using DAHSI.\n",
    "\n",
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfb29b",
   "metadata": {},
   "source": [
    "In this notebook we will show a simple running example of the DAHSI algorithm presented in the paper ... \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858d93b",
   "metadata": {},
   "source": [
    "## Generating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9f035",
   "metadata": {},
   "source": [
    "We will work with the Lorenz system as it is a classical example of chaotic systems.\n",
    "\n",
    "The data we will use for showing a simple running example will be comprised of $N = 501$ time points, with $\\Delta t = 0.01$ and noise ...\n",
    "\n",
    "We will save the time-series for each variable in $\\texttt{.dat}$ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def RK4(f, t, y0, args=()):\n",
    "    n = len(t)\n",
    "    y = np.zeros((n, len(y0)))\n",
    "    y[0] = y0\n",
    "    for i in range(n - 1):\n",
    "        h = t[i+1] - t[i]\n",
    "        k1 = f(t[i], y[i], *args)\n",
    "        k2 = f(t[i] + h / 2., y[i] + k1 * h / 2., *args)\n",
    "        k3 = f(t[i] + h / 2., y[i] + k2 * h / 2., *args)\n",
    "        k4 = f(t[i] + h, y[i] + k3 * h, *args)\n",
    "        y[i+1] = y[i] + (h / 6.) * (k1 + 2*k2 + 2*k3 + k4)\n",
    "    return y\n",
    "\n",
    "def lorenz_K(t, y, sigma, rho, beta):\n",
    "    return np.array([sigma * (y[1] - y[0]), \n",
    "                     y[0]*(rho - y[2]) - y[1], \n",
    "                     y[0]* y[1] - beta*y[2]])\n",
    "\n",
    "# Generate data\n",
    "y0 = [-8.0, 7.0, 27.0]\n",
    "sigma = 10.0\n",
    "rho = 28.0\n",
    "beta = 8.0/3\n",
    "\n",
    "dt = 0.01\n",
    "N = 500+1\n",
    "tfin = dt * (N - 1)\n",
    "t = np.linspace(0, tfin, N)\n",
    "\n",
    "sol = RK4(lorenz_K, t, y0, args=(sigma,rho,beta))\n",
    "\n",
    "x = sol[:,0]\n",
    "y = sol[:,1]\n",
    "z = sol[:,2]\n",
    "\n",
    "xfile = open(\"datax_Lorenz.dat\", \"w\")\n",
    "yfile = open(\"datay_Lorenz.dat\", \"w\")\n",
    "zfile = open(\"dataz_Lorenz.dat\", \"w\")\n",
    "\n",
    "for i in range(N):\n",
    "    xfile.write(\"%.5f\\n\" % x[i])\n",
    "    yfile.write(\"%.5f\\n\" % y[i])\n",
    "    zfile.write(\"%.5f\\n\" % z[i])\n",
    "\n",
    "xfile.close()    \n",
    "yfile.close()    \n",
    "zfile.close()    \n",
    "\n",
    "# Plot\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "ax.plot(x, y, z, lw=2)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "ax.set_title(\"Lorenz Attractor\")\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00fc56",
   "metadata": {},
   "source": [
    "First we are going to look into how we define the generic equations, parameters, bounds etc. To do so, we will load $\\texttt{File1.txt}$ and go over each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf43e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat File1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b46126",
   "metadata": {},
   "source": [
    "We see that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python compile.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83bca6",
   "metadata": {},
   "source": [
    "Now that we have the data, we start by importing all the modules and functions needed to run our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812baa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from header import *\n",
    "\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "\n",
    "from PyIpopt_Funks import *\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle \n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import OneLoopInC\n",
    "\n",
    "from OneLoopInC import eval_f_tricky\n",
    "\n",
    "from OneLoopInC import eval_grad_f_tricky\n",
    "\n",
    "from OneLoopInC import eval_h_tricky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58471fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the variables needed from ObjNeed.obj created in Define_JacHess.py\n",
    "file_ObjJacHess = open('ObjJacHess.obj', 'rb') \n",
    "\n",
    "ObjFunk_Meas_eval = pickle.load(file_ObjJacHess)\n",
    "ObjFunk_Model_eval = pickle.load(file_ObjJacHess)\n",
    "Jacobian_Meas = pickle.load(file_ObjJacHess)\n",
    "Jacobian_Model = pickle.load(file_ObjJacHess)\n",
    "Hessian_Meas = pickle.load(file_ObjJacHess)\n",
    "Hessian_Model = pickle.load(file_ObjJacHess)\n",
    "row_final = pickle.load(file_ObjJacHess)\n",
    "col_final = pickle.load(file_ObjJacHess)\n",
    "nnzh = pickle.load(file_ObjJacHess)\n",
    "\n",
    "def eval_f(x):\n",
    "    assert len(x) == num_total\n",
    "    \n",
    "    return eval_f_tricky(x,Rf)\n",
    "\n",
    "def eval_grad_f(x):\n",
    "    assert len(x) == num_total\n",
    "    \n",
    "    return eval_grad_f_tricky(x,Rf)\n",
    "    \n",
    "def eval_h(x,lagrange,obj_factor,flag):\n",
    "    if flag:\n",
    "        return (np.array(col_final),np.array(row_final))\n",
    "    else:\n",
    "        return eval_h_tricky(x,lagrange,obj_factor,flag,Rf)\n",
    "        \n",
    "class DAHSI():\n",
    "    def objective(self, x):\n",
    "        \"\"\"Returns the scalar value of the objective given x.\"\"\"\n",
    "        return eval_f_tricky(x,Rf)\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"Returns the gradient of the objective with respect to x.\"\"\"\n",
    "        return np.transpose(eval_grad_f_tricky(x,Rf))\n",
    "\n",
    "    def constraints(self, x):\n",
    "        \"\"\"Returns the constraints.\"\"\"\n",
    "        return array([ ], float_)\n",
    "\n",
    "    def jacobian(self, x):\n",
    "        \"\"\"Returns the Jacobian of the constraints with respect to x.\"\"\"\n",
    "        return np.array([])\n",
    "\n",
    "    def hessianstructure(self):\n",
    "        \"\"\"Returns the row and column indices for non-zero vales of the\n",
    "        Hessian.\"\"\"\n",
    "\n",
    "        # NOTE: The default hessian structure is of a lower triangular matrix,\n",
    "        # therefore this function is redundant. It is included as an example\n",
    "        # for structure callback.\n",
    "\n",
    "#        return np.nonzero(np.tril(np.ones((num_total, num_total))))    \n",
    "        return (np.array(col_final),np.array(row_final))\n",
    "\n",
    "    def hessian(self, x, lagrange, obj_factor):\n",
    "        \"\"\"Returns the non-zero values of the Hessian.\"\"\"        \n",
    "        H = eval_h_tricky(x,lagrange,obj_factor,0,Rf)        \n",
    "\n",
    "        row, col = self.hessianstructure()\n",
    "\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c429d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose seed for random number generation.\n",
    "IC = 0\n",
    "np.random.seed(IC)\n",
    "\n",
    "# Bounds for both state variables and parameters. \n",
    "x_L = np.ones((num_total))\n",
    "x_U = np.ones((num_total))\n",
    "\n",
    "for i in range(num_vars):\n",
    "    x_L[i:-num_params:num_vars] = float(Input1[1+2*num_vars+num_params+i].split(\",\")[0])\n",
    "    x_U[i:-num_params:num_vars] = float(Input1[1+2*num_vars+num_params+i].split(\",\")[1])\n",
    "for i in range(num_params):\n",
    "    x_L[-num_params+i] = float(Input1[1+3*num_vars+num_params+i].split(\",\")[0])\n",
    "    x_U[-num_params+i] = float(Input1[1+3*num_vars+num_params+i].split(\",\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc427210",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"D%s_M%s_IC%s_Lorenz.dat\" % (num_vars, num_meas, IC) \n",
    "file_results = os.path.join(\"outputfiles\",file_name)\n",
    "f = open(file_results,\"w+\")\n",
    "\n",
    "lambd = lambd_0\n",
    "\n",
    "x_jp = np.zeros((num_total))    \n",
    "\n",
    "# Use appropriate initial conditions: for state variables, random; for parameters, set them all to 0.\n",
    "x0 = (x_U-x_L)*np.random.rand(num_total)+x_L      \n",
    "for i in range(num_meas):\n",
    "    for k in range(0,num_vars*num_tpoints,num_vars):\n",
    "        x0[k+i] = data[int(k/num_vars),i] \n",
    "for i in range(num_params):    \n",
    "    x0[i-num_params] = 0\n",
    "        \n",
    "for i in range(num_total):\n",
    "    x_jp[i] = x0[i]\n",
    "\n",
    "lb = x_L\n",
    "ub = x_U\n",
    "\n",
    "cl = np.array([])\n",
    "cu = np.array([])\n",
    "\n",
    "nlp = cyipopt.Problem(\n",
    "   n=num_total,\n",
    "   m=0,\n",
    "   problem_obj=DAHSI(),\n",
    "   lb=lb,\n",
    "   ub=ub,\n",
    "   cl=cl,\n",
    "   cu=cu,\n",
    ")\n",
    "\n",
    "# Change some options of the solver.\n",
    "nlp.add_option('linear_solver', 'ma97')\n",
    "#nlp.add_option('max_iter',100)\n",
    "#nlp.add_option('tol',1.e-12)\n",
    "nlp.add_option('mu_strategy', 'adaptive')\n",
    "nlp.add_option('adaptive_mu_globalization', 'never-monotone-mode')\n",
    "#nlp.add_option('bound_relax_factor', 0)\n",
    "nlp.add_option('print_level',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aae620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here starts the main loop\n",
    "while lambd < lambd_max:   \n",
    "    f = open(file_results,\"a+\")\n",
    "\t\n",
    "    Rf0 = 1e-2\n",
    "\n",
    "    for i in range(num_total):\n",
    "        x_jp[i] = x0[i]    \n",
    "\n",
    "    ax = plt.figure()\n",
    "    for beta in tqdm_notebook(range(beta_max+1)):\n",
    "        f = open(file_results,\"a+\")\n",
    "        # Make note in results file which \\lambda and \\beta we are at.\n",
    "        f.write(\"%f %f \" % (lambd, beta))        \n",
    "\n",
    "        # Controlling how much the model is enforced.\n",
    "        Rf = Rf0*(alpha**beta)\n",
    "  \n",
    "        # Solve it via IPOPT (solution is x_jn).    \n",
    "        x_jn, info = nlp.solve(x_jp)\n",
    "            \n",
    "        obj = info['obj_val']\n",
    "        \n",
    "        # We hard threshold the parameter part of the solution (the last num_params elements).\n",
    "        for i in range(num_params):\n",
    "    \t    if abs(x_jn[i-num_params]) < lambd:\n",
    "    \t        x_jn[i-num_params] = 0\n",
    "\n",
    "        # We set this solution as the initial condition for the next iteration of IPOPT. \n",
    "        x_jp = x_jn   \n",
    "\n",
    "        # Write cost function value in file.\n",
    "        f.write(\"%e \" % obj)\n",
    "        \n",
    "        plt.semilogy(beta, obj, 'bo', markersize=10)\n",
    "        \n",
    "        #for k in range(num_total):\n",
    "        #    f.write(\"%f \" % x_jp[k])\n",
    "        #f.write(\"\\n\")  \n",
    "\n",
    "        for k in range(num_params):\n",
    "    \t    f.write(\"%f \" % x_jp[k-num_params])\n",
    "        f.write(\"\\n\")     \n",
    "        \n",
    "        f.close()\n",
    "\n",
    "    # Increase \\lambda value.       \n",
    "    lambd = lambd+0.5\n",
    "f.close()    \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "plt.xlabel(\"\\\\beta\")\n",
    "plt.ylabel(\"log(action)\")\n",
    "# ax.set_title(\"\")\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f697ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = np.loadtxt('outputfiles/D3_M3_IC0_Lorenz.dat', unpack = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be44f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa2814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760048d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
